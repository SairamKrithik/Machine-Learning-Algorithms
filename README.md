#### This repository contains basic implementations of Machine Learning techniques and models using Python packages.

### The packages used for the implementation are:
- **Pandas**
- **Numpy**
- **Scikit-Learn**
- **Scikit-Learn Extra**
- **Seaborn**
- **Matplotlib**

### Process of Machine Learning:
<img src="https://th.bing.com/th/id/R.18b2c5d236f6eb542fa26cdfb1159442?rik=0Uj%2f99spn10r5Q&riu=http%3a%2f%2fwww.favouriteblog.com%2fwp-content%2fuploads%2f2017%2f07%2fMachine-Learning-Process.png&ehk=L%2fme4zOnlKLGikRPxgi9QgJeREVnZutGfoMAwQ12iak%3d&risl=&pid=ImgRaw&r=0" alt="ML Process">

### The algorithms are organized into two main categories:
- **Supervised Learning**
- **Unsupervised Learning**

# Machine Learning Algorithms

## Algorithms Overview

### Supervised Learning

1. **Linear Regression**:
   - Predicts a continuous dependent variable based on the linear relationship between independent variables.
   - **Example Use Case**: Predicting house prices, sales forecasting.
<img src="https://www.researchgate.net/profile/Hieu-Tran-17/publication/340271573/figure/fig3/AS:874657431437319@1585545990533/Linear-Regression-model-sample-illustration.ppm" alt="Linear_Regression">

2. **Logistic Regression**:
   - Used for binary classification problems. It predicts the probability that a given input belongs to a certain class.
   - **Example Use Case**: Spam detection, medical diagnosis.
<p align="center">
<img src="https://miro.medium.com/max/1400/1*44qV8LhNzE5hPnta2PaaHw.png" alt="Logistic_Regression" style="width:30%;height:auto">
</p>

3. **Decision Trees**:
   - A tree-like model used to make decisions based on a series of feature values.
   - **Example Use Case**: Customer segmentation, loan approval.
<p align="center">
<img src="https://pantelis.github.io/cs634/docs/common/lectures/decision-trees/images/fruit-decision-tree.png#center" alt="Descision_Trees" style="width:30%;height:auto">
</p>

4. **Support Vector Machines (SVM)**:
   - A powerful classification algorithm that finds the optimal hyperplane to separate data into different classes.
   - **Example Use Case**: Image classification, text categorization.
<p align="center">
<img src="https://dataaspirant.com/wp-content/uploads/2020/12/3-Support-Vector-Machine-Algorithm.png" alt="SVM" style="width:30%;height:auto">
</p>

### Unsupervised Learning

1. **K-Means Clustering**:
   - Divides data into `k` clusters based on similarity, where each data point belongs to the nearest cluster mean.
   - **Example Use Case**: Market segmentation, document clustering.
<p align="center">
<img src="https://th.bing.com/th/id/OIP.B8eA04Be2Bl9CZZljLLCVQAAAA?rs=1&pid=ImgDetMain" alt="K_Clustering" width="500" height="600">
</p>

2. **Hierarchical Clustering**:\
   - Builds a tree-like structure (dendrogram) to represent nested clusters of data.
   - **Example Use Case**: Gene expression analysis, social network analysis.
<p align="center">
<img src="https://dataaspirant.com/wp-content/uploads/2020/12/17-Hierarchical-Divisive-Clustering.png" alt="Heirarchial_Clustering" width="500" height="600">
</p>

3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**:
   - Identifies clusters of varying shapes based on density, separating noise or outliers from the clusters.
   - **Example Use Case**: Anomaly detection, geospatial data analysis.
<p align="center">
<img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/db6-e1584577503359.png" alt="DB" width="500" height="600">
</p>

4. **Principal Component Analysis (PCA)**:
   - A dimensionality reduction technique that transforms data into a lower-dimensional space while preserving most of the variance in the data.
   - **Example Use Case**: Reducing the dimensionality of high-dimensional datasets, improving computational efficiency in ML models.
<p align="center">
<img src="https://numxl.com/wp-content/uploads/principal-component-analysis-pca-featured-1024x576.png" alt="PCA" width="500" height="600">
</p>
